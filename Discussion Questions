Discussion Questions

Recursion

1) Recursion occurs when a function calls itself within itself. It is useful
    because you don't necessarily need to know everything about what you're
    recursing on. Recursion can provide instances of runtime improvements, but
    at the expense of memory because of increased use of the function call stack.

2) It's necessary to have a base case to ensure that recursion won't continue
    indefinitely. The recursion must progress towards an end point, like a while
    loop must progress towards a terminating case. This is achieved because the
    base case is fundamentally different than other cases. The base case can be
    degenerate, such as an empty list, at which point recursion could not
    continue because there is nothing more to recurse on. Other bases cases must
    be more explicit.


Graphs

1) A graph is a data structure made up of nodes and edges. Nodes contain
    information about what other nodes they share an edge with (also said, are
    adjacent to), meaning they are connected to one another. The information
    about its defined relationships is stored in an adjacency list on each node.

2) A tree is different than a graph in that it's nodes can only have one parent,
    whereas nodes in a graph can have multiple parents. This also means that 
    graphs can have cycles (directed graph), whereas trees are more structured
    and each node can only be reached by one path. Graphs can also be define 
    relationships (undirected).

3) Because graphs are good for defining relationships, they are used for social
    media platforms like Facebook.


Performance of Different Data Structures

Data Structure        Index     Search     Add-R     Add-L    Pop-L   Pop-R
Python List (Array)    O(1)      O(n)       O(1)     O(n)     O(n)    O(1)  
Linked List            O(n)      O(n)       O(1)     O(1)     O(1)    O(n)
Doubly-Linked List     O(n)      O(n)       O(1)     O(1)     O(1)    O(1)
Queue (Array)           X         X         O(1)       X      O(n)      X
Queue (LL/DLL)          X         X         O(1)       X      O(1)      X
Stack (Array/LL/DLL)    X         X         O(1)       X        X     O(1)
Deque (DLL)             X         X         O(1)     O(1)     O(1)    O(1)       

notes to review: how LL Add-R is O(1) (tail?), indexing for LL/DLL
    --> because multiplication, again, just like arrays. although the nodes of a
        LL may not be stored in contiguous memory, the references to those nodes
        are stored in a contiguous memory array, so indexing is also O(1)


Data Structure          Get       Add       Delete      Iterate     Memory
Dictionary (Hash Map)   O(1)      O(1)       O(1)       O(nlogn)    medium
Set (Hash Map)          O(1)      O(1)       O(1)       O(nlogn)    medium
Binary Search Tree     O(logn)   O(logn)    O(logn)       O(n)      light
Tree                    O(n)     O(logn)     O(1)         O(n)      light

notes to review: memory, BST and tree, iteration for hashmaps
    --> Iterating is never better than O(logn). you have to go through logn depth of tree,
        but then it depends on how many nodes are on each level - O(n)



Sorting

1. In each iteration, bubble sort will drag the largest item found and move it
    to the end of the list. Then the same thing happens to the remaining list,
    minus the element just sorted. This ensures that each time the next largest
    element is sorted. If an iteration occurs where no swaps take place, then
    the list is sorted and can be returned without verifying the order of the
    remaining elements.

2. Merge sort will sort two sorted lists. Given a list, merge sort will
    recursively slice the list into two at it's midpoint and  continue to slice
    the produced lists into halves until it reaches it's base case, at which a
    list's length is one zero or empty. This is the base case because an empty 
    list or a list of one element is sorted. Then it reconstructs the sorted 
    lists by comparing the first element in each list and adding them in sorted
    order to the new list.


3. Like merge sort, quick sort begins by finding the midpoint of the list,
    assuming a list greater than 0 or 1 (base case, same as in merge sort). Then
    quicksort arranges the remaining elements in the list into new lists based
    on whether their values are higher than, lower than or equivalent than the
    midpoint, refered to as a pivot. The list of items with equivalent value to
    the pivot are sorted, so quick sort is recursively called on the lower list
    and the higher list for each of those to be sorted. Then the lists are 
    combined in order.

